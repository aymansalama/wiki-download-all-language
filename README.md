# wiki-download-all-language


Downloading all wikipedia

This is the first task is to obtain the whole wikipedia corpus of data. Here is an example of the download link. The bz2 xml file which contains all the data in xml format and compressed in bz2. Gensim library for word2vec can process xml and bz2 files. 
https://dumps.wikimedia.org/enwiki/20171220/enwiki-20171220-pages-articles.xml.bz2
Please note that you can change the date to get the most updated wiki
https://dumps.wikimedia.org/backup-index.html

Please notice the two letter in bold which represent the language. I have download the list of language code from wikipedia 
https://en.wikipedia.org/wiki/List_of_Wikipedias
I have developed a script that download the files in Appendix 1 in this document. The total size of all files of wikipedia is 67G bz2 xml. 
Download starts in 	2017-12-24 15:40:14
Download ends 	2017-12-25 03:32:44 

